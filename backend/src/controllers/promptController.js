import Prompt from '../models/Prompt.js';
import Response from '../models/Response.js';
import User from '../models/User.js';
import AIAggregatorService from '../services/aiAggregatorService.js';
import ScoringService from '../services/scoringService.js';

/**
 * Controller pour g√©rer les prompts et l'agr√©gation IA
 */

/**
 * POST /api/prompts - Cr√©er un nouveau prompt et obtenir les r√©ponses agr√©g√©es
 */
export const createPrompt = async (req, res) => {
  try {
    const { promptText, aiModels, parameters } = req.body;
    const userId = req.user?._id; // Depuis le middleware auth

    // Validation
    if (!promptText || !aiModels || aiModels.length === 0) {
      return res.status(400).json({
        error: 'Prompt text and at least one AI model are required'
      });
    }

    console.log(`\nüìù New prompt from user ${userId}: "${promptText.substring(0, 50)}..."`);

    // Cr√©er le prompt dans la DB
    const prompt = await Prompt.create({
      userId,
      promptText,
      aiModels,
      parameters: parameters || {},
      status: 'processing'
    });

    // Obtenir les clients AI (depuis req.app.locals)
    const aiAggregator = new AIAggregatorService(req.app.locals.aiClients);
    const scoringService = new ScoringService();

    const startTime = Date.now();

    // Agr√©ger les r√©ponses
    const aggregatedResponses = await aiAggregator.aggregateResponses(
      promptText,
      aiModels,
      parameters || {}
    );

    // Calculer les scores
    const scoredResponses = scoringService.scoreAllResponses(
      aggregatedResponses,
      promptText
    );

    const processingTime = Date.now() - startTime;

    // Sauvegarder les r√©ponses dans la DB
    const savedResponses = [];
    for (const response of scoredResponses) {
      const responseDoc = await Response.create({
        promptId: prompt._id,
        aiModel: response.model,
        responseText: response.responseText || '',
        responseTime: response.responseTime,
        tokens: response.tokens,
        scores: response.scores,
        nlpAnalysis: response.nlpAnalysis || {},
        status: response.status,
        error: response.error
      });
      savedResponses.push(responseDoc);
    }

    // Mettre √† jour le prompt
    const successfulResponses = scoredResponses.filter(r => r.status === 'success').length;
    prompt.status = successfulResponses > 0 ? 'completed' : 'failed';
    prompt.metadata = {
      processingTime,
      totalResponses: scoredResponses.length,
      successfulResponses,
      failedResponses: scoredResponses.length - successfulResponses
    };
    await prompt.save();

    // Mettre √† jour les stats utilisateur
    if (userId) {
      await User.findByIdAndUpdate(userId, {
        $inc: { 'stats.totalPrompts': 1, 'stats.totalAnalyses': successfulResponses }
      });
    }

    // G√©n√©rer le r√©sum√© comparatif
    const summary = scoringService.generateComparativeSummary(scoredResponses);

    // Calculer la matrice de similarit√©
    const similarityMatrix = scoringService.calculateSimilarityMatrix(scoredResponses);

    console.log(`‚úÖ Prompt processed successfully in ${processingTime}ms`);

    res.status(201).json({
      prompt: {
        id: prompt._id,
        text: prompt.promptText,
        models: prompt.aiModels,
        status: prompt.status,
        createdAt: prompt.createdAt
      },
      responses: savedResponses,
      summary,
      similarityMatrix,
      metadata: {
        processingTime,
        totalResponses: scoredResponses.length,
        successfulResponses,
        failedResponses: scoredResponses.length - successfulResponses
      }
    });

  } catch (error) {
    console.error('‚ùå Error creating prompt:', error);
    res.status(500).json({
      error: 'Failed to process prompt',
      message: error.message
    });
  }
};

/**
 * GET /api/prompts - R√©cup√©rer l'historique des prompts
 */
export const getPrompts = async (req, res) => {
  try {
    const userId = req.user?._id;
    const { limit = 20, skip = 0, status } = req.query;

    const query = userId ? { userId } : {};
    if (status) query.status = status;

    const prompts = await Prompt.find(query)
      .sort({ createdAt: -1 })
      .limit(parseInt(limit))
      .skip(parseInt(skip))
      .select('-__v');

    const total = await Prompt.countDocuments(query);

    res.json({
      prompts,
      pagination: {
        total,
        limit: parseInt(limit),
        skip: parseInt(skip),
        hasMore: skip + prompts.length < total
      }
    });

  } catch (error) {
    console.error('‚ùå Error fetching prompts:', error);
    res.status(500).json({
      error: 'Failed to fetch prompts',
      message: error.message
    });
  }
};

/**
 * GET /api/prompts/:id - R√©cup√©rer un prompt sp√©cifique avec ses r√©ponses
 */
export const getPromptById = async (req, res) => {
  try {
    const { id } = req.params;

    const prompt = await Prompt.findById(id);

    if (!prompt) {
      return res.status(404).json({ error: 'Prompt not found' });
    }

    // R√©cup√©rer toutes les r√©ponses associ√©es
    const responses = await Response.find({ promptId: id });

    // G√©n√©rer le r√©sum√© et la matrice
    const scoringService = new ScoringService();
    const summary = scoringService.generateComparativeSummary(responses);
    const similarityMatrix = scoringService.calculateSimilarityMatrix(responses);

    res.json({
      prompt,
      responses,
      summary,
      similarityMatrix
    });

  } catch (error) {
    console.error('‚ùå Error fetching prompt:', error);
    res.status(500).json({
      error: 'Failed to fetch prompt',
      message: error.message
    });
  }
};

/**
 * DELETE /api/prompts/:id - Supprimer un prompt
 */
export const deletePrompt = async (req, res) => {
  try {
    const { id } = req.params;
    const userId = req.user?._id;

    const prompt = await Prompt.findById(id);

    if (!prompt) {
      return res.status(404).json({ error: 'Prompt not found' });
    }

    // V√©rifier que l'utilisateur est le propri√©taire
    if (userId && prompt.userId.toString() !== userId.toString()) {
      return res.status(403).json({ error: 'Unauthorized' });
    }

    // Supprimer les r√©ponses associ√©es
    await Response.deleteMany({ promptId: id });

    // Supprimer le prompt
    await Prompt.findByIdAndDelete(id);

    res.json({ message: 'Prompt deleted successfully' });

  } catch (error) {
    console.error('‚ùå Error deleting prompt:', error);
    res.status(500).json({
      error: 'Failed to delete prompt',
      message: error.message
    });
  }
};

/**
 * GET /api/models - R√©cup√©rer les mod√®les IA disponibles
 */
export const getAvailableModels = async (req, res) => {
  try {
    const aiAggregator = new AIAggregatorService(req.app.locals.aiClients);
    const models = aiAggregator.getAvailableModels();

    res.json({
      models,
      count: models.length
    });

  } catch (error) {
    console.error('‚ùå Error fetching models:', error);
    res.status(500).json({
      error: 'Failed to fetch available models',
      message: error.message
    });
  }
};

export default {
  createPrompt,
  getPrompts,
  getPromptById,
  deletePrompt,
  getAvailableModels
};
